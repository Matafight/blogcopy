title: Multi-dimensional Classification
date: 2015-10-10 11:03:53
categories: 机器学习
tags:
---
#bayesian network#
最近在看Multi-dimensional Classification 的相关内容，

**一.Definition**

Multi-dimensional Classification ，即 多输出分类，传统的分类问题只有一个输出，可以看作是一维的，输出的类别是一个维度的，比如说对一个人的性别进行分类，分为男和女，也可以单独对性格进行分类，可以是外向的和内向的。多输出分类与普通的分类不同的地方在于它是对多个维度同时进行的，也即输出的类别是一个向量，现在多输出分类方法可以直接对这个人的多个属性进行分类，比如性别，性格，年龄等，这些输出组成一个多维度的向量，比如:[男，外向，23]。

**二.Some Naive Solutions**

1.将多个输出的属性组成一个Compound Class ,也即将各个属性进行排列组合，每一个不同的组合作为一个复合类别，比如上面中的[男，外向，23]可以整体看作一个类别,而[男，外向，22]则看作另外一个类别，假设共有n个维度，每个维度有k个待选的值，则新的复合类共有k的n次方个。将问题转换成复合类之后就可以用普通的分类方法来分类了，如SVM，Naive-Bayes 等，这种方法有个很明显的缺陷就是复合类的个数过多，训练时间会很长。

2.为每个维度的属性单独训练一个分类器，然后将各个分类器组合起来形成一个大的分类器，但是这种方法忽视了类之间的相关性，假设各个类之间有一个联合概率分布，那么用这种方法训练出来的分类器就相当于各个类关于联合概率分布的边缘概率分布，忽视了类与类可能存在的依赖性，从而丢失了重要信息。

**三.Bayesian Network Classifier （Directed graphical models）**

一种比较流行的解决Multi-dimensional Classification 的方法是利用贝叶斯网络，该网络是个有向无环图，所有的输入特征和输出类均看作节点，节点之间的连线表示变量之间的条件相关性（Conditional dependence）。

*1.preliminary-about graphical models*

现在假如不考虑变量之间的条件独立性，我们考虑所有输入特征和输出属性的联合概率分布，则根据链式法则：

$$p(x_{1:v})=p(x_1)p(x_2|x_1)\ldots p(x_v|x_{1:v-1})$$

其中v是变量的个数（包括特征和输出的类别）,并且

$p(x_{1:v})=p(x_1,x_2,\ldots,x_v)$,

这个方法的困难之处在于，当t增大时，会需要很多的参数来描述条件概率

$p(x_t|x_{1:t-1})$。

如果用 Conditional Probability tables （CPTs）来描述的话，需要$O(K^v)$个参数，所以我们需要很多很多的数据来学习这些参数。

这就引出了条件独立的概念，如果给定Z的值，X和Y相互独立，则X,Y条件独立于Z，记作

$X\perp Y|Z$,并且有:$$X\perp Y |Z \Leftrightarrow p(X,Y|Z)=p(X|Z)p(Y|Z)$$

（有向）图模型是表示联合概率分布的一种方法，并且它还做了条件独立性的假设，图模型中节点表示变量，节点之间的连线表示变量之间的相关性，只要给定指定节点的父节点，该指定节点独立于除了该节点的子节点之外的其他所有节点，这就是条件独立性，由于引入了条件独立性的概念，描述这个图的联合概率分布就可以简化成：

$$p(x_{1:v}|G)=\prod^V_{t=1}p(x_t|X_{pa(t)})$$

其中$p(x_t|X_{pa(t)})$是条件概率分布函数,Xpa(t) 表示节点t的所有父节点，如果每个节点有F个父节点，并且每个节点有K个状态，那么这个模型中的参数个数为$O(VK^F)$,比原来的参数个数$O(K^V)$要少得多。

*2. bayesian network classifiers*

可以利用贝叶斯网络分类器来解决多输出这个问题，贝叶斯网络也就是有向图，它通过为所有的特征建立一个有向无环图来表示特征之间的依赖关系，这个图称为Features subgraph 即特征子图，也为所有的class 建立一个有向无环图来表示类之间的相互关系，称为Class subgraph。同时为了联系特征与类，在所有的特征与类之间也建立一个二分图来联系两个集合中的变量，一般称作Feature selection graph。

为了求解这类问题，必须先学习得到这个图模型的结构，也即变量之间具体的依赖关系。但是如果不添加一些限制条件的话，这基本上是一个NP-hard问题。

通过对结构做各种不同的假定，产生了各种不同的网络来解决多输出问题。