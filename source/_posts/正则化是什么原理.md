title: "正则化是什么原理?"
date: 2015-05-12 10:36:16
categories: 机器学习
tags: 正则化
---

我们一般都会添加正则化项防止过拟合，那么到底是为什么呢？

所谓过拟合就是模型在训练数据集上的误差小，而在测试数据上的误差大。
**为什么会产生过拟合呢？**
1. 参数过多
2. noise
3. 训练样本数少,训练样本数少导致会有很多

**怎样对付过拟合呢？**
想起来老师上课说怎么对付维数灾难了：
1. 增加先验知识
2. 尽可能使target function 光滑
3. 降维

总结一下发现过拟合和正则化也可以从这三个方面来解释：

1. 使用正则项是为了获得一个光滑的function，因为过拟合的函数一般为了能够拟合很多训练数据，其函数图像都是非常陡峭的，何谓光滑？直观上看就是函数的导数比较小，当我们训练一个给定次数的模型时，导数的大小是由系数决定的，所以，想让导数尽量小，就必须让系数尽量小，所以就有了正则项了，即对系数进行惩罚，让系数尽可能小。

2. 还可以从贝叶斯的角度来理解，相当于加了先验知识

3. 从统计的角度来理解,就是最小平方误差的期望最小，希望实现bias-variance trade-off


<script src="https://gist.github.com/Matafight/5e69f893e25916c444d6.js"></script>

参考：[http://www.zhihu.com/question/20700829](http://www.zhihu.com/question/20700829)