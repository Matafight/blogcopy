title: 广义线性模型
date: 2017-09-17 19:58:44
categories: 机器学习
tags: machien learning
---

## 什么是广义线性模型

假设现在有一个预测任务，其输入是$x_i(1\le i \le n)$,对应的label 是$y_i$，我们知道可以用线性模型建模为:

$$
y = \omega^Tx+b
$$

广义线性模型一个最简单的解释是，存在一个单调可微的连接函数$g(\cdot)$满足:

$$
g(y) = \omega^Tx+b
$$

那么模型:$y = g^{-1}(\omega^Tx+b)$就是广义线性模型。

## 指数分布族
上面说到了广义线性模型需要确定一个连接函数，那么连接函数怎么确定呢?当然单调可微的函数都符合条件，但是狭义上的广义线性模型是与指数分布族这个概念联系在一起的。假设样本标号$y$的分布属于指数分布族，那么就存在一个相对应的连接函数使得$(x,y)$可以用广义线性模型建模。

指数分布族的形式如下：

$$
p(y,\eta)=b(y)exp(\eta^TT(y)-a(\eta))
$$
其中$\eta = \omega^Tx$(将b也嵌入到$\omega$中)。

## 从线性回归到逻辑斯谛回归
很多分布都属于指数分布族，如高斯分布，二项分布，泊松分布等。这里以高斯分布和二项分布为例推导广义线性模型。

### 高斯分布与线性模型
假设$y=\omega^Tx+\epsilon$，其中$\epsilon \sim N(0,\sigma^2)$,则有y服从正态分布$y\sim N(\omega^Tx,\sigma^2)$,将这个正态分布展开:

$$
p(y;\eta) = \frac{1}{\sqrt{2\pi}\sigma}exp(-\frac{(y-\eta)^2}{2\sigma^2})
$$
将其展开成指数分布族的形式:

$$
p(y;\eta) = \frac{1}{\sqrt{2\pi}\sigma}exp(-\frac{y^2}{2\sigma^2})exp(\frac{y\omega^Tx}{\sigma^2}-\frac{(\omega^Tx)^2}{2\sigma^2})
$$

所以对应着指数分布族有:

$$b(y) =  \frac{1}{\sqrt{2\pi}\sigma}exp(-\frac{y^2}{2\sigma^2}) 
$$

$$T(y) = \frac{y}{\sigma^2}$$

$$
\eta= \omega^Tx
$$

$$
a(\eta) = \frac{(\omega^Tx)^2}{2\sigma^2}
$$
由第三行公式$\eta= \omega^Tx$可知线性模型的连接函数就是恒等函数


### 二项分布与逻辑斯谛回归
假设$y\in\{-1,1\}$,也就是说这是一个二分类任务，则样本label服从二项分布:

$$
p(y)=\pi^y(1-\pi)^{(1-y)}$$
其中$\pi$表示样本为正例的概率，将其变换成指数分布族的形式:

$$
p(y) = exp(ylog(\pi)+(1-y)log(1-\pi))
$$

$$
=exp(ylog(\frac{y}{1-y})+log(1-\pi))
$$
则有:

$$
b(y) = 1
$$

$$
T(y) = y$$

$$
\eta=log(\frac{\pi}{1-\pi})
$$

$$
a(\eta) = log(1-\pi)
$$

由$\eta=log(\frac{\pi}{1-\pi})$可推出sigmoid函数:

$$
\pi = \frac{e^{\eta}}{1+e^{\eta}}
$$

因此对于二项分布来说，其连接函数是sigmoid函数。由此可推出Logistic Regression，也能看出LR的输出范围是0-1，可以看作是样本为正例的概率。
